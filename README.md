Overview
This project focuses on building a simple language processor, covering key stages of language processing, including tokenization, syntax analysis, and code execution. The language processor consists of three core components: the Lexical Analyzer, the Parser, and the Interpreter, each of which plays a crucial role in ensuring proper code execution.

Features
Lexical Analyzer (Tokenizer):

The Lexical Analyzer processes the input code and splits it into meaningful tokens. These tokens include:
Keywords
Identifiers
Operators
Literals
Punctuation
It ensures proper categorization of these tokens to prepare for the next stages in processing. Tokenization helps detect invalid characters or undefined symbols early in the process, preventing further errors.
Parser:

Using Extended Backus-Naur Form (EBNF), the Parser defines the grammar rules for the language and builds a syntax tree from the tokens generated by the Lexical Analyzer.
The parser checks for syntax errors (like mismatched parentheses, invalid statement order, or incorrect grammar), providing error messages for invalid syntax.
A syntax tree is generated, representing the structure of the input program. This tree will later guide the code execution phase.
Error handling is implemented to catch and report issues like undefined variables, incorrect data types, and runtime errors.
Interpreter:

The Interpreter translates the parsed syntax tree into executable instructions. It executes the instructions sequentially while performing run-time error checking.
Some key run-time errors handled include:
Type mismatches (e.g., adding a string to an integer)
Undefined variables (variables used before being declared)
Invalid operations (e.g., division by zero)
The interpreter ensures smooth execution by catching and handling errors gracefully without crashing.
How It Works
Input: The user provides a source code file written in a custom language.
Tokenization: The Lexical Analyzer processes the input and converts it into tokens.
Syntax Analysis: The Parser checks the sequence of tokens against predefined grammatical rules (defined in EBNF) to build a syntax tree.
Execution: The Interpreter traverses the syntax tree and executes the code step-by-step, handling errors and returning results.
Use Cases
Educational Tool: This project can serve as a learning resource for those interested in compiler design or the workings of interpreters.
Code Validation: The processor can validate and execute small programs written in a simple custom language, making it useful for syntax validation and code execution testing.
Error Handling: It provides comprehensive error messages for both syntax and runtime issues, helping users understand common programming mistakes.
Technologies Used
C++: Core implementation of the lexical analyzer, parser, and interpreter.
EBNF: Used to define the grammar and syntax rules of the language.
Error Handling: Custom exception handling for managing both syntax and runtime errors.
